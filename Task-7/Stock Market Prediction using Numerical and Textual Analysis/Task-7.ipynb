{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 7 : Stock Market Prediction using Numerical and Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Dataset from Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader.data import DataReader\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['Date','Category','News']\n",
    "ndf = pd.read_csv(\"india-news-headlines.csv\",names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing part of the whole dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>publish_date</td>\n",
       "      <td>headline_category</td>\n",
       "      <td>headline_text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>unknown</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date           Category  \\\n",
       "0  publish_date  headline_category   \n",
       "1      20010102            unknown   \n",
       "2      20010102            unknown   \n",
       "3      20010102            unknown   \n",
       "4      20010102            unknown   \n",
       "\n",
       "                                                News  \n",
       "0                                      headline_text  \n",
       "1  Status quo will not be disturbed at Ayodhya; s...  \n",
       "2                Fissures in Hurriyat over Pak visit  \n",
       "3              America's unwanted heading for India?  \n",
       "4                 For bigwigs; it is destination Goa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Showing part of the whole dataset:')\n",
    "ndf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing part of the whole dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>News</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20010102</td>\n",
       "      <td>Status quo will not be disturbed at Ayodhya; s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20010102</td>\n",
       "      <td>Fissures in Hurriyat over Pak visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20010102</td>\n",
       "      <td>America's unwanted heading for India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20010102</td>\n",
       "      <td>For bigwigs; it is destination Goa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20010102</td>\n",
       "      <td>Extra buses to clear tourist traffic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650961</th>\n",
       "      <td>20220331</td>\n",
       "      <td>Garment industry jittery over'GST hike'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650962</th>\n",
       "      <td>20220331</td>\n",
       "      <td>AAP MLAs interfering in work: Councillors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650963</th>\n",
       "      <td>20220331</td>\n",
       "      <td>Schools organise vax camps for kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650964</th>\n",
       "      <td>20220331</td>\n",
       "      <td>Madhya Pradesh CM Shivraj Singh Chouhan promis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650965</th>\n",
       "      <td>20220331</td>\n",
       "      <td>bhopal endures first heatwave max temp crosses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3650965 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date                                               News\n",
       "1        20010102  Status quo will not be disturbed at Ayodhya; s...\n",
       "2        20010102                Fissures in Hurriyat over Pak visit\n",
       "3        20010102              America's unwanted heading for India?\n",
       "4        20010102                 For bigwigs; it is destination Goa\n",
       "5        20010102               Extra buses to clear tourist traffic\n",
       "...           ...                                                ...\n",
       "3650961  20220331            Garment industry jittery over'GST hike'\n",
       "3650962  20220331          AAP MLAs interfering in work: Councillors\n",
       "3650963  20220331                Schools organise vax camps for kids\n",
       "3650964  20220331  Madhya Pradesh CM Shivraj Singh Chouhan promis...\n",
       "3650965  20220331  bhopal endures first heatwave max temp crosses...\n",
       "\n",
       "[3650965 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.drop(0, inplace=True)\n",
    "ndf.drop('Category', axis = 1, inplace=True)\n",
    "print('Showing part of the whole dataset:')\n",
    "ndf.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>41052.359375</td>\n",
       "      <td>41401.648438</td>\n",
       "      <td>41005.179688</td>\n",
       "      <td>41352.171875</td>\n",
       "      <td>41352.171875</td>\n",
       "      <td>19000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>41442.750000</td>\n",
       "      <td>41614.769531</td>\n",
       "      <td>41358.468750</td>\n",
       "      <td>41558.570313</td>\n",
       "      <td>41558.570313</td>\n",
       "      <td>24300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>41571.820313</td>\n",
       "      <td>41719.289063</td>\n",
       "      <td>41456.398438</td>\n",
       "      <td>41673.921875</td>\n",
       "      <td>41673.921875</td>\n",
       "      <td>33300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>41746.199219</td>\n",
       "      <td>41809.960938</td>\n",
       "      <td>41636.109375</td>\n",
       "      <td>41681.539063</td>\n",
       "      <td>41681.539063</td>\n",
       "      <td>33600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-23</td>\n",
       "      <td>41548.261719</td>\n",
       "      <td>41701.621094</td>\n",
       "      <td>41474.609375</td>\n",
       "      <td>41642.660156</td>\n",
       "      <td>41642.660156</td>\n",
       "      <td>6200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>44665.910156</td>\n",
       "      <td>45148.281250</td>\n",
       "      <td>44665.910156</td>\n",
       "      <td>45079.550781</td>\n",
       "      <td>45079.550781</td>\n",
       "      <td>27600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>2020-12-07</td>\n",
       "      <td>45099.921875</td>\n",
       "      <td>45458.921875</td>\n",
       "      <td>45024.468750</td>\n",
       "      <td>45426.968750</td>\n",
       "      <td>45426.968750</td>\n",
       "      <td>18700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2020-12-08</td>\n",
       "      <td>45568.800781</td>\n",
       "      <td>45742.230469</td>\n",
       "      <td>45335.171875</td>\n",
       "      <td>45608.511719</td>\n",
       "      <td>45608.511719</td>\n",
       "      <td>18200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>2020-12-09</td>\n",
       "      <td>45891.039063</td>\n",
       "      <td>46164.101563</td>\n",
       "      <td>45792.011719</td>\n",
       "      <td>46103.500000</td>\n",
       "      <td>46103.500000</td>\n",
       "      <td>20700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>45999.421875</td>\n",
       "      <td>46043.968750</td>\n",
       "      <td>45685.871094</td>\n",
       "      <td>45959.878906</td>\n",
       "      <td>45959.878906</td>\n",
       "      <td>12700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "0    2019-12-17  41052.359375  41401.648438  41005.179688  41352.171875   \n",
       "1    2019-12-18  41442.750000  41614.769531  41358.468750  41558.570313   \n",
       "2    2019-12-19  41571.820313  41719.289063  41456.398438  41673.921875   \n",
       "3    2019-12-20  41746.199219  41809.960938  41636.109375  41681.539063   \n",
       "4    2019-12-23  41548.261719  41701.621094  41474.609375  41642.660156   \n",
       "..          ...           ...           ...           ...           ...   \n",
       "242  2020-12-04  44665.910156  45148.281250  44665.910156  45079.550781   \n",
       "243  2020-12-07  45099.921875  45458.921875  45024.468750  45426.968750   \n",
       "244  2020-12-08  45568.800781  45742.230469  45335.171875  45608.511719   \n",
       "245  2020-12-09  45891.039063  46164.101563  45792.011719  46103.500000   \n",
       "246  2020-12-10  45999.421875  46043.968750  45685.871094  45959.878906   \n",
       "\n",
       "        Adj Close   Volume  \n",
       "0    41352.171875  19000.0  \n",
       "1    41558.570313  24300.0  \n",
       "2    41673.921875  33300.0  \n",
       "3    41681.539063  33600.0  \n",
       "4    41642.660156   6200.0  \n",
       "..            ...      ...  \n",
       "242  45079.550781  27600.0  \n",
       "243  45426.968750  18700.0  \n",
       "244  45608.511719  18200.0  \n",
       "245  46103.500000  20700.0  \n",
       "246  45959.878906  12700.0  \n",
       "\n",
       "[247 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second dataset\n",
    "hisdf = pd.read_csv(\"BSESN.csv\")\n",
    "hisdf.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3650970 entries, 1 to 3650970\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype         \n",
      "---  ------  -----         \n",
      " 0   Date    datetime64[ns]\n",
      " 1   News    object        \n",
      "dtypes: datetime64[ns](1), object(1)\n",
      "memory usage: 55.7+ MB\n"
     ]
    }
   ],
   "source": [
    "ndf[\"Date\"] = pd.to_datetime(ndf[\"Date\"],format='%Y%m%d')\n",
    "ndf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['News'] = ndf.groupby(['Date']).transform(lambda x : ' '.join(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = ndf.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf=hisdf[[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
    "hisdf.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for common information of the second dataset\n",
    "hisdf[\"Date\"]= pd.to_datetime(hisdf[\"Date\"])\n",
    "hisdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hisdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated values\n",
    "hisdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hisdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "hisdf['Close'].plot()\n",
    "plt.ylabel('BSESN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating Unnecessary Characters in News Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.replace(\"[^a-zA-Z']\",\" \",regex=True,inplace=True)\n",
    "ndf[\"News\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = hisdf['Close']\n",
    "\n",
    "ma = close.rolling(window = 50).mean()\n",
    "std = close.rolling(window = 50).std()\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "hisdf['Close'].plot(color='g',label='Close')\n",
    "ma.plot(color = 'r',label='Rolling Mean')\n",
    "std.plot(label = 'Rolling Standard Deviation')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = close / close.shift(1) - 1\n",
    "\n",
    "plt.figure(figsize = (20,10))\n",
    "returns.plot(label='Return', color = 'g')\n",
    "plt.title(\"Returns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = hisdf[:1219]\n",
    "test = hisdf[1219:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Standard Deviation and Rolling mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stationarity test\n",
    "def test_stationarity(timeseries):\n",
    "\n",
    " #Determine the rolling statistics\n",
    " rolmean = timeseries.rolling(20).mean()\n",
    " rolstd = timeseries.rolling(20).std()\n",
    "\n",
    " #Plot rolling statistics:\n",
    " plt.figure(figsize = (20,10))\n",
    " plt.plot(timeseries, color = 'blue', label = 'original')\n",
    " plt.plot(rolmean, color = 'r', label = 'rolling mean')\n",
    " plt.plot(rolstd, color = 'black', label = 'rolling std')\n",
    " plt.xlabel('Date')\n",
    " plt.legend()\n",
    " plt.title('Rolling Mean and Standard Deviation',  fontsize = 30)\n",
    " plt.show(block = False)\n",
    " \n",
    " print('Results of dickey fuller test')\n",
    " result = adfuller(timeseries, autolag = 'AIC')\n",
    " labels = ['ADF Test Statistic','p-value','#Lags Used','Number of Observations Used']\n",
    " for value,label in zip(result, labels):\n",
    "   print(label+' : '+str(value) )\n",
    " if result[1] <= 0.05:\n",
    "   print(\"Strong evidence against the null hypothesis(Ho), reject the null hypothesis. Data is stationary\")\n",
    " else:\n",
    "   print(\"Weak evidence against null hypothesis, time series is non-stationary \")\n",
    "test_stationarity(train['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = np.log(train['Close']) \n",
    "test_log = np.log(test['Close'])\n",
    "\n",
    "mav = train_log.rolling(24).mean() \n",
    "plt.figure(figsize = (20,10))\n",
    "plt.plot(train_log) \n",
    "plt.plot(mav, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log.dropna(inplace = True)\n",
    "test_log.dropna(inplace = True)\n",
    "\n",
    "test_stationarity(train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log_diff = train_log - mav\n",
    "train_log_diff.dropna(inplace = True)\n",
    "\n",
    "test_stationarity(train_log_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = auto_arima(train_log, trace = True, error_action = 'ignore', suppress_warnings = True)\n",
    "model.fit(train_log)\n",
    "predictions = model.predict(periods = len(test))\n",
    "predictions = pd.DataFrame(predictions,index = test_log.index,columns=['Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_log, label='Train')\n",
    "plt.plot(test_log, label='Test')\n",
    "plt.plot(predictions, label='Prediction')\n",
    "plt.title('BSESN Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Actual Stock Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = np.sqrt(mean_squared_error(test_log,predictions))\n",
    "print(\"RMSE : \", rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSubjectivity(text):\n",
    "  return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "def getPolarity(text):\n",
    "  return  TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['Subjectivity'] = ndf['News'].apply(getSubjectivity)\n",
    "ndf['Polarity'] = ndf['News'].apply(getPolarity)\n",
    "ndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf['Compound'] = [sia.polarity_scores(v)['compound'] for v in ndf['News']]\n",
    "ndf['Negative'] = [sia.polarity_scores(v)['neg'] for v in ndf['News']]\n",
    "ndf['Neutral'] = [sia.polarity_scores(v)['neu'] for v in ndf['News']]\n",
    "ndf['Positive'] = [sia.polarity_scores(v)['pos'] for v in ndf['News']]\n",
    "ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Historical and Textual Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(hisdf, ndf, how='inner', on='Date')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation For Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmerge1 = df_merge[['Close','Subjectivity', 'Polarity', 'Compound', 'Negative', 'Neutral', 'Positive']]\n",
    "dfmerge1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "df = pd.DataFrame(scaler.fit_transform(dfmerge1))\n",
    "df.columns = dfmerge1.columns\n",
    "df.index = dfmerge1.index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Close',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df['Close']\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the Dataset into Training and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train, y_train)\n",
    "prediction=rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction[:10])\n",
    "print(y_test[:10])\n",
    "print('Mean Squared error: ',mean_squared_error(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(x_train, y_train)\n",
    "predictions = dtr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions[:10])\n",
    "print(y_test[:10])\n",
    "print('Mean Squared error: ',mean_squared_error(predictions,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostRegressor()\n",
    "adb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = adb.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = lightgbm.LGBMRegressor()\n",
    "gbm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gbm.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBRegressor()\n",
    "xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb.predict(x_test)\n",
    "print(mean_squared_error(predictions, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RandomForest = 0.05257968397499098\n",
    "- DecisionTree = 0.10831900809236311\n",
    "- AdaBoost = 0.05492347045438241\n",
    "- LightGBM = 0.0583079056070462\n",
    "- XGBoost = 0.05968830860645931\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided results, it is evident that RandomForestRegressor outperforms the other regression models in terms of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
